{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVXLEseOZuLk"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gSeLxp2CrL4",
        "outputId": "cf41c6d1-148f-435c-eef0-283e5fde5925"
      },
      "outputs": [],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"bcLcEpxMIQLbehAgWUQa\")\n",
        "project = rf.workspace(\"roboflow-100\").project(\"x-ray-rheumatology\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"yolov5\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QZMsUjCfevu"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "r5fZkdmJFWWO"
      },
      "outputs": [],
      "source": [
        "!pip install -q roboflow ultralytics\n",
        "!pip install -q scikit-learn matplotlib seaborn pandas opencv-python-headless\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 878
        },
        "id": "ZdxFgKsiFUch",
        "outputId": "67fceb07-4798-4007-da4e-9b29cb2606f0"
      },
      "outputs": [],
      "source": [
        "# Import các thư viện\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from roboflow import Roboflow\n",
        "from ultralytics import YOLO\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Thiết lập random seed để tái tạo lại kết quả\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Tải dữ liệu từ Roboflow\n",
        "rf = Roboflow(api_key=\"bcLcEpxMIQLbehAgWUQa\")\n",
        "project = rf.workspace(\"roboflow-100\").project(\"x-ray-rheumatology\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"yolov5\")\n",
        "\n",
        "# Lấy đường dẫn hiện tại\n",
        "# DATA_DIR = Path(os.getcwd()) # This line was causing the error\n",
        "#The dataset is downloaded into a folder with the same name as the project and version\n",
        "# Instead of version.version_number, use version.id to get the version number\n",
        "DATA_DIR = \"/content/x-ray-rheumatology-2\"\n",
        "print(f\"Dữ liệu được tải về thư mục: {DATA_DIR}\")\n",
        "\n",
        "# Hiển thị thông tin về dữ liệu\n",
        "yaml_file = \"/content/x-ray-rheumatology-2/data.yaml\"\n",
        "print(f\"Nội dung file data.yaml:\\n{open(yaml_file).read()}\")\n",
        "\n",
        "# Kiểm tra số lượng ảnh trong mỗi tập\n",
        "# Convert DATA_DIR to a Path object\n",
        "DATA_DIR = Path(DATA_DIR)\n",
        "train_dir = DATA_DIR / 'train' / 'images' # Use / for joining paths with Path objects\n",
        "val_dir = DATA_DIR / 'valid' / 'images'\n",
        "test_dir = DATA_DIR / 'test' / 'images'\n",
        "\n",
        "print(f\"Số lượng ảnh trong tập train: {len(list(train_dir.glob('*.jpg')))}\")\n",
        "print(f\"Số lượng ảnh trong tập validation: {len(list(val_dir.glob('*.jpg')))}\")\n",
        "print(f\"Số lượng ảnh trong tập test: {len(list(test_dir.glob('*.jpg')))}\")\n",
        "\n",
        "# Hiển thị một số ảnh mẫu từ tập huấn luyện\n",
        "def plot_sample_images(image_dir, num_samples=3):\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    sample_images = list(image_dir.glob('*.jpg'))[:num_samples]\n",
        "\n",
        "    for i, img_path in enumerate(sample_images):\n",
        "        img = cv2.imread(str(img_path))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Đọc nhãn tương ứng\n",
        "        label_path = str(img_path).replace('images', 'labels').replace('.jpg', '.txt')\n",
        "\n",
        "        plt.subplot(1, num_samples, i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"Sample {i+1}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('sample_images.png')\n",
        "    plt.show()\n",
        "\n",
        "plot_sample_images(train_dir)\n",
        "\n",
        "# Phân tích phân bố của các lớp\n",
        "def analyze_class_distribution(label_dir, class_names):\n",
        "    class_counts = {name: 0 for name in class_names}\n",
        "\n",
        "    # Đếm số lượng object cho mỗi lớp\n",
        "    for label_file in label_dir.glob('*.txt'):\n",
        "        with open(label_file, 'r') as f:\n",
        "            for line in f:\n",
        "                class_id = int(line.split()[0])\n",
        "                class_counts[class_names[class_id]] += 1\n",
        "\n",
        "    # Vẽ biểu đồ phân bố\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.barplot(x=list(class_counts.keys()), y=list(class_counts.values()))\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.title('Phân bố các lớp trong tập dữ liệu')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('class_distribution.png')\n",
        "    plt.show()\n",
        "\n",
        "    return class_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "id": "noc19Gr6Dsfo",
        "outputId": "b6298d0a-fb7a-40a2-dd67-0628da227a5d"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "with open(yaml_file, 'r') as f:\n",
        "    data_yaml = yaml.safe_load(f)\n",
        "    class_names = data_yaml['names']\n",
        "\n",
        "train_labels_dir = DATA_DIR / 'train' / 'labels'\n",
        "class_counts = analyze_class_distribution(train_labels_dir, class_names)\n",
        "print(\"Số lượng đối tượng cho mỗi lớp:\", class_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W-0IK8_GCvfP",
        "outputId": "83c6a058-aed0-4d6a-bc61-192aa4536911"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U90ju16lgD8K",
        "outputId": "59403cf5-a9dc-4b47-b49b-e37034c6f11a"
      },
      "outputs": [],
      "source": [
        "%cd yolov5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-JFH5zDCvaj"
      },
      "outputs": [],
      "source": [
        "!python train.py --img 640 --batch 16 --epochs 100 --data {DATA_DIR}/data.yaml --weights yolov5s.pt --name x-ray-rheumatology\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-l9aPyDUIn9a"
      },
      "outputs": [],
      "source": [
        "weights_path = Path('/content/yolov5/runs/train/x-ray-rheumatology-continued/weights/best.pt')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXS2oOdB15ug"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HeUR4QJ1Z22",
        "outputId": "b2804f6a-b0d0-4f5e-a601-2fc20c6a4a6f"
      },
      "outputs": [],
      "source": [
        "!python train.py --img 640 --batch 16 --epochs 200 --data {DATA_DIR}/data.yaml --weights runs/train/x-ray-rheumatology3/weights/best.pt --name x-ray-rheumatology-continued"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4JQYYX_IJnS",
        "outputId": "b8cee5ad-7462-446f-c243-a567ea910eb0"
      },
      "outputs": [],
      "source": [
        "!python val.py --weights {weights_path} --data {DATA_DIR}/data.yaml --img 640 --task test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Slkf2BaRztV7"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0x5PT92NqZ2",
        "outputId": "41a6bfee-de09-4f80-b53a-d66838a186ce"
      },
      "outputs": [],
      "source": [
        "!python detect.py --weights {weights_path} --source {test_dir} --conf 0.25 --save-txt --save-conf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WsgAtgGDjsgB",
        "outputId": "4a1dc4e6-4f37-41b9-d0c5-c4e9b2383730"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import albumentations as A\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "import shutil\n",
        "\n",
        "def load_yolo_annotations(annotation_path):\n",
        "    \"\"\"Đọc annotation định dạng YOLO từ file txt\"\"\"\n",
        "    boxes = []\n",
        "    if os.path.exists(annotation_path):\n",
        "        with open(annotation_path, 'r') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) == 5:\n",
        "                    class_id = int(parts[0])\n",
        "                    x_center, y_center = float(parts[1]), float(parts[2])\n",
        "                    width, height = float(parts[3]), float(parts[4])\n",
        "                    boxes.append([class_id, x_center, y_center, width, height])\n",
        "    return np.array(boxes)\n",
        "\n",
        "def yolo_to_pascal_voc(yolo_boxes, img_width, img_height):\n",
        "    \"\"\"Chuyển đổi từ định dạng YOLO sang Pascal VOC (x_min, y_min, x_max, y_max)\"\"\"\n",
        "    pascal_boxes = []\n",
        "    for box in yolo_boxes:\n",
        "        class_id = box[0]\n",
        "        x_center, y_center = box[1], box[2]\n",
        "        width, height = box[3], box[4]\n",
        "\n",
        "        x_min = int((x_center - width/2) * img_width)\n",
        "        y_min = int((y_center - height/2) * img_height)\n",
        "        x_max = int((x_center + width/2) * img_width)\n",
        "        y_max = int((y_center + height/2) * img_height)\n",
        "\n",
        "        pascal_boxes.append([x_min, y_min, x_max, y_max, class_id])\n",
        "\n",
        "    return np.array(pascal_boxes)\n",
        "\n",
        "def pascal_voc_to_yolo(pascal_boxes, img_width, img_height):\n",
        "    \"\"\"Chuyển đổi từ định dạng Pascal VOC sang YOLO\"\"\"\n",
        "    yolo_boxes = []\n",
        "    for box in pascal_boxes:\n",
        "        x_min, y_min, x_max, y_max = box[0], box[1], box[2], box[3]\n",
        "        class_id = box[4]\n",
        "\n",
        "        x_center = ((x_min + x_max) / 2) / img_width\n",
        "        y_center = ((y_min + y_max) / 2) / img_height\n",
        "        width = (x_max - x_min) / img_width\n",
        "        height = (y_max - y_min) / img_height\n",
        "\n",
        "        yolo_boxes.append([class_id, x_center, y_center, width, height])\n",
        "\n",
        "    return np.array(yolo_boxes)\n",
        "\n",
        "def save_yolo_annotations(boxes, output_path):\n",
        "    \"\"\"Lưu annotation định dạng YOLO vào file txt\"\"\"\n",
        "    with open(output_path, 'w') as f:\n",
        "        for box in boxes:\n",
        "            box = [str(round(float(x), 6)) for x in box]\n",
        "            f.write(' '.join(box) + '\\n')\n",
        "\n",
        "def apply_augmentation(image, bboxes, augmentation):\n",
        "    \"\"\"Áp dụng tăng cường dữ liệu cho ảnh và bounding boxes\"\"\"\n",
        "    # Chuyển đổi từ YOLO format sang Pascal VOC format\n",
        "    height, width = image.shape[:2]\n",
        "    pascal_boxes = []\n",
        "    class_labels = []\n",
        "\n",
        "    if len(bboxes) > 0:\n",
        "        for box in bboxes:\n",
        "            class_id = int(box[0])\n",
        "            x_center, y_center = box[1], box[2]\n",
        "            w, h = box[3], box[4]\n",
        "\n",
        "            x_min = int((x_center - w/2) * width)\n",
        "            y_min = int((y_center - h/2) * height)\n",
        "            x_max = int((x_center + w/2) * width)\n",
        "            y_max = int((y_center + h/2) * height)\n",
        "\n",
        "            pascal_boxes.append([x_min, y_min, x_max, y_max])\n",
        "            class_labels.append(class_id)\n",
        "\n",
        "        # Áp dụng augmentation\n",
        "        transformed = augmentation(\n",
        "            image=image,\n",
        "            bboxes=pascal_boxes,\n",
        "            class_labels=class_labels\n",
        "        )\n",
        "\n",
        "        # Lấy kết quả\n",
        "        transformed_image = transformed['image']\n",
        "        transformed_bboxes = transformed['bboxes']\n",
        "        transformed_labels = transformed['class_labels']\n",
        "\n",
        "        # Chuyển đổi bboxes trở lại định dạng YOLO\n",
        "        transformed_yolo = []\n",
        "        h, w = transformed_image.shape[:2]\n",
        "\n",
        "        for i, (x_min, y_min, x_max, y_max) in enumerate(transformed_bboxes):\n",
        "            x_center = ((x_min + x_max) / 2) / w\n",
        "            y_center = ((y_min + y_max) / 2) / h\n",
        "            width_norm = (x_max - x_min) / w\n",
        "            height_norm = (y_max - y_min) / h\n",
        "\n",
        "            transformed_yolo.append([transformed_labels[i], x_center, y_center, width_norm, height_norm])\n",
        "\n",
        "        return transformed_image, np.array(transformed_yolo)\n",
        "\n",
        "    return image, np.array(bboxes)\n",
        "\n",
        "def create_augmentation_pipeline(aug_type='default'):\n",
        "    \"\"\"Tạo pipeline augmentation cho ảnh X-quang\"\"\"\n",
        "    if aug_type == 'default':\n",
        "        return A.Compose([\n",
        "            A.RandomRotate90(p=0.2),\n",
        "            A.HorizontalFlip(p=0.3),\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),\n",
        "            A.GaussNoise(var=15.0, p=0.3),  # Sửa var_limit thành var\n",
        "        ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))\n",
        "\n",
        "    elif aug_type == 'medical':\n",
        "        # Augmentation đặc biệt cho ảnh y tế\n",
        "        return A.Compose([\n",
        "            A.Affine(scale=(0.95, 1.05), translate_percent=(0.02, 0.02), rotate=(-5, 5), p=0.5),  # Thay ShiftScaleRotate\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.2, p=0.5),\n",
        "            A.GaussianBlur(blur_limit=(1, 3), p=0.2),\n",
        "            A.CLAHE(clip_limit=1.5, p=0.3),\n",
        "            A.Equalize(p=0.2),\n",
        "        ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))\n",
        "\n",
        "    elif aug_type == 'strong':\n",
        "        # Augmentation mạnh khi dataset nhỏ\n",
        "        return A.Compose([\n",
        "            A.OneOf([\n",
        "                A.RandomRotate90(p=1.0),\n",
        "                A.Rotate(limit=10, p=1.0),\n",
        "                A.Affine(scale=(0.9, 1.1), translate_percent=(0.05, 0.05), rotate=(-15, 15), p=1.0),  # Thay ShiftScaleRotate\n",
        "            ], p=0.5),\n",
        "            A.OneOf([\n",
        "                A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1.0),\n",
        "                A.CLAHE(clip_limit=2.0, p=1.0),\n",
        "                A.Equalize(p=1.0),\n",
        "            ], p=0.5),\n",
        "            A.OneOf([\n",
        "                A.GaussNoise(var=30.0, p=1.0),  # Sửa var_limit thành var\n",
        "                A.GaussianBlur(blur_limit=(1, 3), p=1.0),\n",
        "                A.MotionBlur(blur_limit=3, p=1.0),\n",
        "            ], p=0.3),\n",
        "            A.OneOf([\n",
        "                A.ElasticTransform(alpha=1, sigma=50, p=1.0),  # Bỏ alpha_affine\n",
        "                A.GridDistortion(num_steps=5, distort_limit=0.3, p=1.0),\n",
        "                A.OpticalDistortion(distort_limit=0.3, shift_limit=0.5, p=1.0),\n",
        "            ], p=0.2),\n",
        "        ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))\n",
        "\n",
        "    elif aug_type == 'ra_specific':\n",
        "        # Tăng cường đặc biệt cho viêm khớp dạng thấp\n",
        "        return A.Compose([\n",
        "            # Biến đổi nhẹ về vị trí và góc quay (do ảnh X-quang thường được chụp ở các góc tiêu chuẩn)\n",
        "            A.Affine(scale=(0.95, 1.05), translate_percent=(0.03, 0.03), rotate=(-7, 7), p=0.5),  # Thay ShiftScaleRotate\n",
        "\n",
        "            # Điều chỉnh tương phản và độ sáng để mô phỏng các điều kiện chụp khác nhau\n",
        "            A.OneOf([\n",
        "                A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.2, p=1.0),\n",
        "                A.CLAHE(clip_limit=2.0, tile_grid_size=(4, 4), p=1.0),\n",
        "                A.Equalize(p=1.0),\n",
        "            ], p=0.7),\n",
        "\n",
        "            # Mô phỏng điều kiện chất lượng ảnh khác nhau\n",
        "            A.OneOf([\n",
        "                A.GaussNoise(var=20.0, p=1.0),  # Sửa var_limit thành var\n",
        "                A.GaussianBlur(blur_limit=(1, 2), p=1.0),\n",
        "                A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=1.0),\n",
        "            ], p=0.3),\n",
        "\n",
        "            # Thêm một số biến đổi rất nhẹ về hình thái để mô phỏng góc chụp khác nhau\n",
        "            A.OneOf([\n",
        "                A.ElasticTransform(alpha=0.5, sigma=25, p=1.0),  # Bỏ alpha_affine\n",
        "                A.GridDistortion(num_steps=3, distort_limit=0.1, p=1.0),\n",
        "            ], p=0.1),\n",
        "        ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))\n",
        "\n",
        "    else:\n",
        "        # Default augmentation\n",
        "        return A.Compose([\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.RandomBrightnessContrast(p=0.2),\n",
        "        ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))\n",
        "\n",
        "def augment_dataset(input_dir, output_dir, class_names, aug_types=['default'],\n",
        "                   num_augmentations=2, visualize=True):\n",
        "    \"\"\"Tạo bộ dữ liệu tăng cường từ bộ gốc\"\"\"\n",
        "    # Tạo thư mục đầu ra\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, 'images'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, 'labels'), exist_ok=True)\n",
        "\n",
        "    # Tìm tất cả các file ảnh\n",
        "    image_paths = []\n",
        "    for ext in ['.jpg', '.jpeg', '.png']:\n",
        "        image_paths.extend(list(Path(os.path.join(input_dir, 'images')).glob(f'*{ext}')))\n",
        "\n",
        "    # Tạo pipeline tăng cường\n",
        "    augmentations = {}\n",
        "    for aug_type in aug_types:\n",
        "        augmentations[aug_type] = create_augmentation_pipeline(aug_type)\n",
        "\n",
        "    # Sao chép dữ liệu gốc sang thư mục đầu ra\n",
        "    for img_path in image_paths:\n",
        "        img_name = img_path.name\n",
        "        label_path = os.path.join(input_dir, 'labels', img_name.rsplit('.', 1)[0] + '.txt')\n",
        "\n",
        "        # Sao chép ảnh gốc\n",
        "        shutil.copy(str(img_path), os.path.join(output_dir, 'images', img_name))\n",
        "\n",
        "        # Sao chép nhãn gốc nếu tồn tại\n",
        "        if os.path.exists(label_path):\n",
        "            shutil.copy(label_path, os.path.join(output_dir, 'labels', img_name.rsplit('.', 1)[0] + '.txt'))\n",
        "\n",
        "    # Tạo dữ liệu tăng cường\n",
        "    for img_path in image_paths:\n",
        "        img_name = img_path.name\n",
        "        base_name = img_name.rsplit('.', 1)[0]\n",
        "        img_ext = img_name.rsplit('.', 1)[1]\n",
        "        label_path = os.path.join(input_dir, 'labels', base_name + '.txt')\n",
        "\n",
        "        # Đọc ảnh\n",
        "        image = cv2.imread(str(img_path))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Đọc annotation\n",
        "        bboxes = load_yolo_annotations(label_path)\n",
        "\n",
        "        # Áp dụng tăng cường\n",
        "        for aug_idx in range(num_augmentations):\n",
        "            for aug_type, aug_pipeline in augmentations.items():\n",
        "                try:\n",
        "                    # Áp dụng pipeline tương ứng\n",
        "                    aug_image, aug_bboxes = apply_augmentation(image.copy(), bboxes.copy(), aug_pipeline)\n",
        "\n",
        "                    # Tạo tên file mới\n",
        "                    new_img_name = f\"{base_name}_{aug_type}_{aug_idx}.{img_ext}\"\n",
        "                    new_label_name = f\"{base_name}_{aug_type}_{aug_idx}.txt\"\n",
        "\n",
        "                    # Lưu ảnh mới\n",
        "                    aug_image_rgb = cv2.cvtColor(aug_image, cv2.COLOR_RGB2BGR)\n",
        "                    cv2.imwrite(os.path.join(output_dir, 'images', new_img_name), aug_image_rgb)\n",
        "\n",
        "                    # Lưu annotation mới\n",
        "                    if len(aug_bboxes) > 0:\n",
        "                        save_yolo_annotations(aug_bboxes, os.path.join(output_dir, 'labels', new_label_name))\n",
        "\n",
        "                    # Hiển thị kết quả tăng cường nếu cần\n",
        "                    if visualize and aug_idx == 0:\n",
        "                        fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "                        # Hiển thị ảnh gốc với bboxes\n",
        "                        ax[0].imshow(image)\n",
        "                        ax[0].set_title(f\"Ảnh gốc\")\n",
        "                        height, width = image.shape[:2]\n",
        "                        for box in bboxes:\n",
        "                            class_id, x_center, y_center, w, h = box\n",
        "                            x1 = int((x_center - w/2) * width)\n",
        "                            y1 = int((y_center - h/2) * height)\n",
        "                            x2 = int((x_center + w/2) * width)\n",
        "                            y2 = int((y_center + h/2) * height)\n",
        "\n",
        "                            rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, fill=False, edgecolor='red', linewidth=2)\n",
        "                            ax[0].add_patch(rect)\n",
        "                            if class_names and int(class_id) < len(class_names):\n",
        "                                ax[0].text(x1, y1, class_names[int(class_id)], color='white',\n",
        "                                         bbox=dict(facecolor='red', alpha=0.5))\n",
        "\n",
        "                        # Hiển thị ảnh tăng cường với bboxes\n",
        "                        ax[1].imshow(aug_image)\n",
        "                        ax[1].set_title(f\"Tăng cường: {aug_type}\")\n",
        "                        height, width = aug_image.shape[:2]\n",
        "                        for box in aug_bboxes:\n",
        "                            class_id, x_center, y_center, w, h = box\n",
        "                            x1 = int((x_center - w/2) * width)\n",
        "                            y1 = int((y_center - h/2) * height)\n",
        "                            x2 = int((x_center + w/2) * width)\n",
        "                            y2 = int((y_center + h/2) * height)\n",
        "\n",
        "                            rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, fill=False, edgecolor='blue', linewidth=2)\n",
        "                            ax[1].add_patch(rect)\n",
        "                            if class_names and int(class_id) < len(class_names):\n",
        "                                ax[1].text(x1, y1, class_names[int(class_id)], color='white',\n",
        "                                         bbox=dict(facecolor='blue', alpha=0.5))\n",
        "                except Exception as e:\n",
        "                    print(f\"Lỗi khi xử lý ảnh {img_name} với augmentation {aug_type}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "    # Tạo file data.yaml cho bộ dữ liệu mới\n",
        "    yaml_content = {\n",
        "        'train': './images',\n",
        "        'val': './images',  # Thường nên tách riêng tập validation\n",
        "        'test': './images',  # Thường nên tách riêng tập test\n",
        "        'nc': len(class_names),\n",
        "        'names': class_names\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(output_dir, 'data.yaml'), 'w') as f:\n",
        "        yaml.dump(yaml_content, f)\n",
        "\n",
        "    # Báo cáo kết quả\n",
        "    original_count = len(image_paths)\n",
        "    augmented_count = original_count * (1 + len(aug_types) * num_augmentations)\n",
        "\n",
        "    print(f\"Đã tạo bộ dữ liệu tăng cường:\")\n",
        "    print(f\"- Số lượng ảnh gốc: {original_count}\")\n",
        "    print(f\"- Số lượng ảnh sau tăng cường: {augmented_count}\")\n",
        "    print(f\"- Tỉ lệ tăng cường: {augmented_count / original_count:.2f}x\")\n",
        "    print(f\"- Các phương pháp tăng cường đã sử dụng: {', '.join(aug_types)}\")\n",
        "    print(f\"- Bộ dữ liệu mới được lưu tại: {output_dir}\")\n",
        "\n",
        "    return output_dir\n",
        "\n",
        "class_names = ['artefact', 'distal phalanges', 'fifth metacarpal bone', 'first metacarpal bone',\n",
        "              'fourth metacarpal bone', 'intermediate phalanges', 'proximal phalanges', 'radius',\n",
        "              'second metacarpal bone', 'soft tissue calcination', 'third metacarpal bone', 'ulna']\n",
        "\n",
        "# Tạo bộ dữ liệu tăng cường với nhiều loại kỹ thuật\n",
        "augment_dataset(\n",
        "    input_dir='/content/x-ray-rheumatology-2/train',\n",
        "    output_dir='/content/augmented_dataset',\n",
        "    class_names=class_names,\n",
        "    aug_types=['default', 'medical', 'ra_specific'],  # Sử dụng nhiều loại augmentation\n",
        "    num_augmentations=2,    # Tăng số lượng ảnh cho mỗi loại\n",
        "    visualize=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2G4cLd7mnfVq",
        "outputId": "23e17188-d8dc-450d-cc9d-07e2215336d0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Thư mục nguồn\n",
        "aug_dataset_dir = '/content/augmented_dataset'\n",
        "images_dir = os.path.join(aug_dataset_dir, 'images')\n",
        "labels_dir = os.path.join(aug_dataset_dir, 'labels')\n",
        "\n",
        "# Tạo các thư mục cần thiết\n",
        "train_img_dir = os.path.join(aug_dataset_dir, 'train', 'images')\n",
        "train_label_dir = os.path.join(aug_dataset_dir, 'train', 'labels')\n",
        "val_img_dir = os.path.join(aug_dataset_dir, 'valid', 'images')\n",
        "val_label_dir = os.path.join(aug_dataset_dir, 'valid', 'labels')\n",
        "test_img_dir = os.path.join(aug_dataset_dir, 'test', 'images')\n",
        "test_label_dir = os.path.join(aug_dataset_dir, 'test', 'labels')\n",
        "\n",
        "# Tạo thư mục nếu chưa tồn tại\n",
        "os.makedirs(train_img_dir, exist_ok=True)\n",
        "os.makedirs(train_label_dir, exist_ok=True)\n",
        "os.makedirs(val_img_dir, exist_ok=True)\n",
        "os.makedirs(val_label_dir, exist_ok=True)\n",
        "os.makedirs(test_img_dir, exist_ok=True)\n",
        "os.makedirs(test_label_dir, exist_ok=True)\n",
        "\n",
        "# Lấy danh sách tất cả các ảnh\n",
        "all_images = list(Path(images_dir).glob('*.jpg'))\n",
        "import random\n",
        "random.shuffle(all_images)\n",
        "\n",
        "# Chia tập dữ liệu (80% train, 10% validation, 10% test)\n",
        "total = len(all_images)\n",
        "train_count = int(total * 0.8)\n",
        "val_count = int(total * 0.1)\n",
        "\n",
        "train_images = all_images[:train_count]\n",
        "val_images = all_images[train_count:train_count+val_count]\n",
        "test_images = all_images[train_count+val_count:]\n",
        "\n",
        "# Di chuyển các file vào thư mục tương ứng\n",
        "for img_path in train_images:\n",
        "    img_name = img_path.name\n",
        "    label_name = img_name.rsplit('.', 1)[0] + '.txt'\n",
        "    label_path = os.path.join(labels_dir, label_name)\n",
        "\n",
        "    shutil.copy(str(img_path), os.path.join(train_img_dir, img_name))\n",
        "    if os.path.exists(label_path):\n",
        "        shutil.copy(label_path, os.path.join(train_label_dir, label_name))\n",
        "\n",
        "for img_path in val_images:\n",
        "    img_name = img_path.name\n",
        "    label_name = img_name.rsplit('.', 1)[0] + '.txt'\n",
        "    label_path = os.path.join(labels_dir, label_name)\n",
        "\n",
        "    shutil.copy(str(img_path), os.path.join(val_img_dir, img_name))\n",
        "    if os.path.exists(label_path):\n",
        "        shutil.copy(label_path, os.path.join(val_label_dir, label_name))\n",
        "\n",
        "for img_path in test_images:\n",
        "    img_name = img_path.name\n",
        "    label_name = img_name.rsplit('.', 1)[0] + '.txt'\n",
        "    label_path = os.path.join(labels_dir, label_name)\n",
        "\n",
        "    shutil.copy(str(img_path), os.path.join(test_img_dir, img_name))\n",
        "    if os.path.exists(label_path):\n",
        "        shutil.copy(label_path, os.path.join(test_label_dir, label_name))\n",
        "\n",
        "print(f\"Đã tổ chức lại bộ dữ liệu:\")\n",
        "print(f\"- Train: {len(train_images)} ảnh\")\n",
        "print(f\"- Validation: {len(val_images)} ảnh\")\n",
        "print(f\"- Test: {len(test_images)} ảnh\")\n",
        "\n",
        "# Cập nhật file data.yaml với đường dẫn tuyệt đối\n",
        "yaml_path = os.path.join(aug_dataset_dir, 'data.yaml')\n",
        "with open(yaml_path, 'r') as f:\n",
        "    yaml_content = yaml.safe_load(f)\n",
        "\n",
        "yaml_content['train'] = '/content/augmented_dataset/train/images'\n",
        "yaml_content['val'] = '/content/augmented_dataset/valid/images'\n",
        "yaml_content['test'] = '/content/augmented_dataset/test/images'\n",
        "\n",
        "with open(yaml_path, 'w') as f:\n",
        "    yaml.dump(yaml_content, f)\n",
        "\n",
        "print(\"Đã cập nhật file data.yaml với đường dẫn tuyệt đối\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCgx5N4ATIs8",
        "outputId": "accd7ffc-c04b-46c7-ee79-9cf20ae0a500"
      },
      "outputs": [],
      "source": [
        "!python train.py --img 640 --batch 16 --epochs 100 --data /content/augmented_dataset/data.yaml --weights yolov5s.pt --name ra_augmented"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfP7oBYDnPra"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
